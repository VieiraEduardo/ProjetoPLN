{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Dr4uWxx/3gP2haVFMfLX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VieiraEduardo/ProjetoPLN/blob/main/5_Processamento_de_linguagem_natural_(PLN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processamento de Linguagem Natural\n",
        "\n",
        "*   Este exemplo irei mostrar como usar técnicas de NLP para análisar textos, extrair insights, classificar sentimentos e transoformar e transformar textos não estruturados em dados estruturados úteis. Essas técnicas podem ser aplicadas a diversos cados de uso, como análise de sentimentos de produtos, feedback de clientes e muito mais.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xHOV8l3kdnG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Preparar e carregar os dados\n",
        "\n",
        "irei usar um conjunto de dados fictícios de análise de produtos."
      ],
      "metadata": {
        "id": "MVSENWkUefnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPUJc48PdF10",
        "outputId": "e5dc4d89-251c-4345-8dd1-e424668cec51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dados carregados:\n",
            "                                              review\n",
            "0                   This product is great! I love it\n",
            "1  Terrible customer service. I am very disappoin...\n",
            "2                           The quality is fantastic\n",
            "3             Not worth the money. Very poor quality\n",
            "4       I am extremely satisfied with this purchase.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#Criação de um DataFrame fictício com análises de produtos\n",
        "data= {\n",
        "    \"review\": [\n",
        "        \"This product is great! I love it\",\n",
        "        \"Terrible customer service. I am very disappointed.\",\n",
        "        \"The quality is fantastic\",\n",
        "        \"Not worth the money. Very poor quality\",\n",
        "        \"I am extremely satisfied with this purchase.\"\n",
        "\n",
        "    ]\n",
        "}\n",
        "df=pd.DataFrame(data)\n",
        "print(\"dados carregados:\")\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Pré-processar os textos\n",
        "\n",
        "\n",
        "*   Limpando os textos convertendo para minúsculos, removendo pontuações, tokennizando, removendo stopwords e lematizando.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cj1aKrSbjIPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk #é uma das bibliotecas mais populares e poderosas para NLP em Python\n",
        "from nltk.corpus import stopwords #módulo do nltk que contém uma lista de palaras comuns que geralmente são removidas durante o pré processamento de textos em tarefas\n",
        "from nltk.tokenize import word_tokenize #módulo do nltk que é usada para dividir um texto em palavras individuais ( tokens )\n",
        "from nltk.stem import WordNetLemmatizer #módulo do nltk que é usada para reduzir palavras a sua forma base ou raiz ( lemmas )\n",
        "import string #contém diversas constantes e clsses úteis para manipulação de strings\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "  #Converter o texto para minúsculos\n",
        "  text=text.lower()\n",
        "  #Remover pontuações\n",
        "  text=text.translate(str.maketrans('', '', string.punctuation))\n",
        "  #Tokenizar o texto\n",
        "  tokens=word_tokenize(text)\n",
        "  #Remover stopwords\n",
        "  text=[word for word in tokens if word not in stopwords.words('english')]\n",
        "  #Lematizar as palavras\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  text=[lemmatizer.lemmatize(word) for word in text]\n",
        "  #juntar as palavras de volta a uma string\n",
        "  text=' '.join(text)\n",
        "  return text\n",
        "#Aplicar a função de pré processamento\n",
        "df[\"cleaned_review\"]=df[\"review\"].apply(preprocess_text)\n",
        "print(\"\\nTextos pré-processdos:\")\n",
        "print(df[\"cleaned_review\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVe_0wli4BF",
        "outputId": "8e107ef1-4bcc-45ac-853b-3ef1f2586b06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Textos pré-processdos:\n",
            "0                        product great love\n",
            "1    terrible customer service disappointed\n",
            "2                         quality fantastic\n",
            "3                  worth money poor quality\n",
            "4              extremely satisfied purchase\n",
            "Name: cleaned_review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Classificar Sentimentos"
      ],
      "metadata": {
        "id": "s8b9LLlQs6T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob #fornece uma API simples para tarefas  comuns de NLP, como análise de sentimentos, tradução, correção gramatical, tokenização e muito mais\n",
        "def classify_sentiment(text):\n",
        "    analysis=TextBlob(text)\n",
        "    #Classificar como positivo, negativo ou neutro\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return \"positive\"\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "#Aplicar a função de classificação de sentimento\n",
        "df[\"sentiment\"]=df[\"cleaned_review\"].apply(classify_sentiment)\n",
        "print(\"\\nClassificação de sentimentos:\")\n",
        "print(df[[\"review\", \"sentiment\"]])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifgT8L7Pnr03",
        "outputId": "3c08293d-6d0b-4cba-97a7-f4b6ef186d0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classificação de sentimentos:\n",
            "                                              review sentiment\n",
            "0                   This product is great! I love it  positive\n",
            "1  Terrible customer service. I am very disappoin...  negative\n",
            "2                           The quality is fantastic  positive\n",
            "3             Not worth the money. Very poor quality  negative\n",
            "4       I am extremely satisfied with this purchase.  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Extrair Insigths"
      ],
      "metadata": {
        "id": "9Sn5R-4iu7Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter #Módulo de python que fornece ferramentas para trabalhar com coleções\n",
        "#Contagem das palavras\n",
        "all_words=' '.join(df[\"cleaned_review\"])\n",
        "word_freq=Counter(all_words.split())\n",
        "print(\"\\nPalavras mais frequentes:\")\n",
        "print(word_freq.most_common(10))\n",
        "\n",
        "#Contagem de sentimentos\n",
        "sentiment_counts=df[\"sentiment\"].value_counts()\n",
        "print(\"\\nContagem de sentimentos:\")\n",
        "print(sentiment_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soRqFRuts5Io",
        "outputId": "c3367ff1-e6e5-419b-d940-08f50179c076"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palavras mais frequentes:\n",
            "[('quality', 2), ('product', 1), ('great', 1), ('love', 1), ('terrible', 1), ('customer', 1), ('service', 1), ('disappointed', 1), ('fantastic', 1), ('worth', 1)]\n",
            "\n",
            "Contagem de sentimentos:\n",
            "sentiment\n",
            "positive    3\n",
            "negative    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Transformar textos em dados estruturados\n",
        "\n"
      ],
      "metadata": {
        "id": "AXJL6JyhwJIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # módulo do scikit-learn que é usado para extrair recursos de texto\n",
        "# Transformar textos em uma representação vetorial TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "\n",
        "# Mostrar a matriz TF-IDF\n",
        "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(\"\\nMatriz TF-IDF:\")\n",
        "print(tfidf_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqrUlUaGwTny",
        "outputId": "6d8ac198-ec0e-49c2-fb30-656aa053cd80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz TF-IDF:\n",
            "   customer  disappointed  extremely  fantastic    great     love     money  \\\n",
            "0       0.0           0.0    0.00000   0.000000  0.57735  0.57735  0.000000   \n",
            "1       0.5           0.5    0.00000   0.000000  0.00000  0.00000  0.000000   \n",
            "2       0.0           0.0    0.00000   0.778283  0.00000  0.00000  0.000000   \n",
            "3       0.0           0.0    0.00000   0.000000  0.00000  0.00000  0.523358   \n",
            "4       0.0           0.0    0.57735   0.000000  0.00000  0.00000  0.000000   \n",
            "\n",
            "       poor  product  purchase   quality  satisfied  service  terrible  \\\n",
            "0  0.000000  0.57735   0.00000  0.000000    0.00000      0.0       0.0   \n",
            "1  0.000000  0.00000   0.00000  0.000000    0.00000      0.5       0.5   \n",
            "2  0.000000  0.00000   0.00000  0.627914    0.00000      0.0       0.0   \n",
            "3  0.523358  0.00000   0.00000  0.422242    0.00000      0.0       0.0   \n",
            "4  0.000000  0.00000   0.57735  0.000000    0.57735      0.0       0.0   \n",
            "\n",
            "      worth  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.000000  \n",
            "3  0.523358  \n",
            "4  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "# Salvar o DataFrame como um arquivo CSV\n",
        "tfidf_df.to_csv('matriz-tf-idf.csv', index=True)"
      ],
      "metadata": {
        "id": "GOmopi_36Pus"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Baixar o arquivo CSV para pasta local\n",
        "files.download('matriz-tf-idf.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6fMdKcGc7uFT",
        "outputId": "116d8a39-2cad-4f87-a96a-e5039da1ea76"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e683582-ba4a-43eb-9ed3-27b4bb78a1bd\", \"matriz-tf-idf.csv\", 613)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}